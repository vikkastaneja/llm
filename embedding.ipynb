{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59077d56",
   "metadata": {},
   "source": [
    "We will use already built token embeddings <br/>\n",
    "[word2vec-google-news-300](https://huggingface.co/fse/word2vec-google-news-300)<br/>\n",
    "Pre-trained vectors trained on a part of the Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases. The phrases were obtained using a simple data-driven approach described in 'Distributed Representations of Words and Phrases and their Compositionality'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a6a8b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e9a09ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/vtaneja/Python_Common/common_venv/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.3.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in /Users/vtaneja/Python_Common/common_venv/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp312-cp312-macosx_11_0_arm64.whl (24.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-macosx_12_0_arm64.whl (30.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.4/30.4 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading smart_open-7.3.1-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: smart-open, scipy, gensim\n",
      "\u001b[2K  Attempting uninstall: scipy\n",
      "\u001b[2K    Found existing installation: scipy 1.15.2\n",
      "\u001b[2K    Uninstalling scipy-1.15.2:\n",
      "\u001b[2K      Successfully uninstalled scipy-1.15.2━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [scipy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [gensim]2m2/3\u001b[0m [gensim]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "yolov5 7.0.14 requires huggingface-hub<0.25.0,>=0.12.0, but you have huggingface-hub 0.33.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gensim-4.3.3 scipy-1.13.1 smart-open-7.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1202011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# import gensim.downloader as api\n",
    "# Uncomment the code when downloading model directly from web\n",
    "# model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a87816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model into gensim's native format\n",
    "# model.save(\"word2vec-google-news-300.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310b1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from file\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load(\"word2vec-google-news-300.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "663f44ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.07421875e-01 -2.01171875e-01  1.23046875e-01  2.11914062e-01\n",
      " -9.13085938e-02  2.16796875e-01 -1.31835938e-01  8.30078125e-02\n",
      "  2.02148438e-01  4.78515625e-02  3.66210938e-02 -2.45361328e-02\n",
      "  2.39257812e-02 -1.60156250e-01 -2.61230469e-02  9.71679688e-02\n",
      " -6.34765625e-02  1.84570312e-01  1.70898438e-01 -1.63085938e-01\n",
      " -1.09375000e-01  1.49414062e-01 -4.65393066e-04  9.61914062e-02\n",
      "  1.68945312e-01  2.60925293e-03  8.93554688e-02  6.49414062e-02\n",
      "  3.56445312e-02 -6.93359375e-02 -1.46484375e-01 -1.21093750e-01\n",
      " -2.27539062e-01  2.45361328e-02 -1.24511719e-01 -3.18359375e-01\n",
      " -2.20703125e-01  1.30859375e-01  3.66210938e-02 -3.63769531e-02\n",
      " -1.13281250e-01  1.95312500e-01  9.76562500e-02  1.26953125e-01\n",
      "  6.59179688e-02  6.93359375e-02  1.02539062e-02  1.75781250e-01\n",
      " -1.68945312e-01  1.21307373e-03 -2.98828125e-01 -1.15234375e-01\n",
      "  5.66406250e-02 -1.77734375e-01 -2.08984375e-01  1.76757812e-01\n",
      "  2.38037109e-02 -2.57812500e-01 -4.46777344e-02  1.88476562e-01\n",
      "  5.51757812e-02  5.02929688e-02 -1.06933594e-01  1.89453125e-01\n",
      " -1.16210938e-01  8.49609375e-02 -1.71875000e-01  2.45117188e-01\n",
      " -1.73828125e-01 -8.30078125e-03  4.56542969e-02 -1.61132812e-02\n",
      "  1.86523438e-01 -6.05468750e-02 -4.17480469e-02  1.82617188e-01\n",
      "  2.20703125e-01 -1.22558594e-01 -2.55126953e-02 -3.08593750e-01\n",
      "  9.13085938e-02  1.60156250e-01  1.70898438e-01  1.19628906e-01\n",
      "  7.08007812e-02 -2.64892578e-02 -3.08837891e-02  4.06250000e-01\n",
      " -1.01562500e-01  5.71289062e-02 -7.26318359e-03 -9.17968750e-02\n",
      " -1.50390625e-01 -2.55859375e-01  2.16796875e-01 -3.63769531e-02\n",
      "  2.24609375e-01  8.00781250e-02  1.56250000e-01  5.27343750e-02\n",
      "  1.50390625e-01 -1.14746094e-01 -8.64257812e-02  1.19140625e-01\n",
      " -7.17773438e-02  2.73437500e-01 -1.64062500e-01  7.29370117e-03\n",
      "  4.21875000e-01 -1.12792969e-01 -1.35742188e-01 -1.31835938e-01\n",
      " -1.37695312e-01 -7.66601562e-02  6.25000000e-02  4.98046875e-02\n",
      " -1.91406250e-01 -6.03027344e-02  2.27539062e-01  5.88378906e-02\n",
      " -3.24218750e-01  5.41992188e-02 -1.35742188e-01  8.17871094e-03\n",
      " -5.24902344e-02 -1.74713135e-03 -9.81445312e-02 -2.86865234e-02\n",
      "  3.61328125e-02  2.15820312e-01  5.98144531e-02 -3.08593750e-01\n",
      " -2.27539062e-01  2.61718750e-01  9.86328125e-02 -5.07812500e-02\n",
      "  1.78222656e-02  1.31835938e-01 -5.35156250e-01 -1.81640625e-01\n",
      "  1.38671875e-01 -3.10546875e-01 -9.71679688e-02  1.31835938e-01\n",
      " -1.16210938e-01  7.03125000e-02  2.85156250e-01  3.51562500e-02\n",
      " -1.01562500e-01 -3.75976562e-02  1.41601562e-01  1.42578125e-01\n",
      " -5.68847656e-02  2.65625000e-01 -2.09960938e-01  9.64355469e-03\n",
      " -6.68945312e-02 -4.83398438e-02 -6.10351562e-02  2.45117188e-01\n",
      " -9.66796875e-02  1.78222656e-02 -1.27929688e-01 -4.78515625e-02\n",
      " -7.26318359e-03  1.79687500e-01  2.78320312e-02 -2.10937500e-01\n",
      " -1.43554688e-01 -1.27929688e-01  1.73339844e-02 -3.60107422e-03\n",
      " -2.04101562e-01  3.63159180e-03 -1.19628906e-01 -6.15234375e-02\n",
      "  5.93261719e-02 -3.23486328e-03 -1.70898438e-01 -3.14941406e-02\n",
      " -8.88671875e-02 -2.89062500e-01  3.44238281e-02 -1.87500000e-01\n",
      "  2.94921875e-01  1.58203125e-01 -1.19628906e-01  7.61718750e-02\n",
      "  6.39648438e-02 -4.68750000e-02 -6.83593750e-02  1.21459961e-02\n",
      " -1.44531250e-01  4.54101562e-02  3.68652344e-02  3.88671875e-01\n",
      "  1.45507812e-01 -2.55859375e-01 -4.46777344e-02 -1.33789062e-01\n",
      " -1.38671875e-01  6.59179688e-02  1.37695312e-01  1.14746094e-01\n",
      "  2.03125000e-01 -4.78515625e-02  1.80664062e-02 -8.54492188e-02\n",
      " -2.48046875e-01 -3.39843750e-01 -2.83203125e-02  1.05468750e-01\n",
      " -2.14843750e-01 -8.74023438e-02  7.12890625e-02  1.87500000e-01\n",
      " -1.12304688e-01  2.73437500e-01 -3.26171875e-01 -1.77734375e-01\n",
      " -4.24804688e-02 -2.69531250e-01  6.64062500e-02 -6.88476562e-02\n",
      " -1.99218750e-01 -7.03125000e-02 -2.43164062e-01 -3.66210938e-02\n",
      " -7.37304688e-02 -1.77734375e-01  9.17968750e-02 -1.25000000e-01\n",
      " -1.65039062e-01 -3.57421875e-01 -2.85156250e-01 -1.66992188e-01\n",
      "  1.97265625e-01 -1.53320312e-01  2.31933594e-02  2.06054688e-01\n",
      "  1.80664062e-01 -2.74658203e-02 -1.92382812e-01 -9.61914062e-02\n",
      " -1.06811523e-02 -4.73632812e-02  6.54296875e-02 -1.25732422e-02\n",
      "  1.78222656e-02 -8.00781250e-02 -2.59765625e-01  9.37500000e-02\n",
      " -7.81250000e-02  4.68750000e-02 -2.22167969e-02  1.86767578e-02\n",
      "  3.11279297e-02  1.04980469e-02 -1.69921875e-01  2.58789062e-02\n",
      " -3.41796875e-02 -1.44042969e-02 -5.46875000e-02 -8.78906250e-02\n",
      "  1.96838379e-03  2.23632812e-01 -1.36718750e-01  1.75781250e-01\n",
      " -1.63085938e-01  1.87500000e-01  3.44238281e-02 -5.63964844e-02\n",
      " -2.27689743e-05  4.27246094e-02  5.81054688e-02 -1.07910156e-01\n",
      " -3.88183594e-02 -2.69531250e-01  3.34472656e-02  9.81445312e-02\n",
      "  5.63964844e-02  2.23632812e-01 -5.49316406e-02  1.46484375e-01\n",
      "  5.93261719e-02 -2.19726562e-01  6.39648438e-02  1.66015625e-02\n",
      "  4.56542969e-02  3.26171875e-01 -3.80859375e-01  1.70898438e-01\n",
      "  5.66406250e-02 -1.04492188e-01  1.38671875e-01 -1.57226562e-01\n",
      "  3.23486328e-03 -4.80957031e-02 -2.48046875e-01 -6.20117188e-02]\n"
     ]
    }
   ],
   "source": [
    "# Example of word as a vector\n",
    "word_vector = model\n",
    "\n",
    "# Let us look how a vector for the word 'computer' looks like\n",
    "print(word_vector['computer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c608022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.KeyedVectors"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb3f9551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(word_vector['computer'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d848699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118192911148071), ('monarch', 0.6189674735069275), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321243286133), ('kings', 0.5236844420433044), ('Queen_Consort', 0.5235945582389832), ('queens', 0.5181134343147278), ('sultan', 0.5098593235015869), ('monarchy', 0.5087411403656006)]\n"
     ]
    }
   ],
   "source": [
    "# Let's see the semantics meaning between words that is kept in these vectors\n",
    "# King + Woman - Man = ??? (similar to queen)\n",
    "print(word_vector.most_similar(positive=['king', 'woman'], negative=['man'], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0769f81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('princess', 0.7421581149101257), ('duchess', 0.6354914307594299)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vector.most_similar(positive=['prince', 'girl'], negative=['boy'], topn=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc3a9e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76640123\n",
      "0.6510956\n",
      "0.5679825\n",
      "0.48621917\n",
      "0.77633655\n",
      "0.43638504\n",
      "0.6081898\n"
     ]
    }
   ],
   "source": [
    "# Check for similarity between a few pair of words\n",
    "print(word_vector.similarity('man', 'woman'))\n",
    "print(word_vector.similarity('king', 'queen'))\n",
    "print(word_vector.similarity('you', 'me'))\n",
    "print(word_vector.similarity('her', 'him'))\n",
    "print(word_vector.similarity('grandpa', 'grandma'))\n",
    "print(word_vector.similarity('tv', 'radio'))\n",
    "print(word_vector.similarity('school','college'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7b43fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('elephants', 0.7806671261787415), ('rhino', 0.678035318851471), ('pachyderm', 0.6761021018028259), ('tiger', 0.6681443452835083), ('rhinoceros', 0.6430983543395996)]\n"
     ]
    }
   ],
   "source": [
    "# Most similar words\n",
    "print(word_vector.most_similar('elephant', topn=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8440c6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnitude diff between man and woman is 1.73\n",
      "Magnitude diff between day and night is 2.01\n",
      "Magnitude diff between paper and cloth is 3.08\n"
     ]
    }
   ],
   "source": [
    "# Similarity between vectors\n",
    "# The more the distance between magnitude of vectors, the more dissimilarity between the words\n",
    "import numpy as np\n",
    "\n",
    "word1 = 'man'\n",
    "word2 = 'woman'\n",
    "\n",
    "vector_diff1 = model[word1] - model[word2]\n",
    "\n",
    "magnitude_diff1 = np.linalg.norm(vector_diff1)\n",
    "\n",
    "print(f'Magnitude diff between {word1} and {word2} is {magnitude_diff1:.2f}')\n",
    "\n",
    "word1 = 'day'\n",
    "word2 = 'night'\n",
    "\n",
    "vector_diff1 = model[word1] - model[word2]\n",
    "\n",
    "magnitude_diff1 = np.linalg.norm(vector_diff1)\n",
    "\n",
    "print(f'Magnitude diff between {word1} and {word2} is {magnitude_diff1:.2f}')\n",
    "\n",
    "word1 = 'paper'\n",
    "word2 = 'cloth'\n",
    "\n",
    "vector_diff1 = model[word1] - model[word2]\n",
    "\n",
    "magnitude_diff1 = np.linalg.norm(vector_diff1)\n",
    "\n",
    "print(f'Magnitude diff between {word1} and {word2} is {magnitude_diff1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81507a",
   "metadata": {},
   "source": [
    "## CREATING TOKEN EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05033153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input_ids = torch.tensor([2,3,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ca54462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(6, 3)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1268,  1.3564, -0.0247],\n",
      "        [-0.8466,  0.0293, -0.5721],\n",
      "        [-1.2546,  0.0486,  0.2753],\n",
      "        [-2.1550, -0.7116,  0.0575],\n",
      "        [ 0.6263, -1.7736, -0.2205],\n",
      "        [ 2.7467, -1.0480,  1.1239]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "torch.manual_seed(100)\n",
    "\n",
    "embedding_matrix = torch.nn.Embedding(vocab_size, output_dim)\n",
    "\n",
    "print(embedding_matrix)\n",
    "print(embedding_matrix.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75b36225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6263, -1.7736, -0.2205]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix(torch.tensor([4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dd80061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2546,  0.0486,  0.2753],\n",
      "        [-2.1550, -0.7116,  0.0575],\n",
      "        [ 2.7467, -1.0480,  1.1239],\n",
      "        [-0.8466,  0.0293, -0.5721]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca4c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "common_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
